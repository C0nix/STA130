{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ebf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "\n",
    "# Read the CSV from the URL using 'latin1' encoding\n",
    "df = pd.read_csv(url, encoding='latin1')\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad39aa",
   "metadata": {},
   "source": [
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771234e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "\n",
    "# Read the CSV from the URL using 'latin1' encoding\n",
    "df = pd.read_csv(url, encoding='latin1')\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(df)\n",
    "\n",
    "# Print the number of rows and columns without changing the display format\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52147e36",
   "metadata": {},
   "source": [
    "In this context, \"observations\" and \"variables\" mean rows and columns respectively. Each \"observation\" represents each row of the dataset that contains infomation such as the name and other characteristics related to it. On the other hand, each \"variable\" shares the same category of infomation. For example, in this particular dataset, the variable(column) \"name\" represents the name of each pokemon. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc8f58",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d683eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "\n",
    "# Read the CSV from the URL using 'latin1' encoding\n",
    "df = pd.read_csv(url, encoding='latin1')\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(df)\n",
    "\n",
    "# Get missing values count using .isna()\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Filter out columns with missing values\n",
    "missing_summary = missing_values[missing_values > 0]\n",
    "\n",
    "# Separate numerical and categorical columns with missing values\n",
    "numerical_missing = [col for col in missing_summary.index if pd.api.types.is_numeric_dtype(df[col])]\n",
    "categorical_missing = [col for col in missing_summary.index if pd.api.types.is_object_dtype(df[col])]\n",
    "\n",
    "# Print the summary of missing data for numerical columns\n",
    "print(\"Missing Data Summary for Numerical Columns:\")\n",
    "for column in numerical_missing:\n",
    "    print(f\"{column}: {missing_summary[column]} missing\")\n",
    "\n",
    "# Print the summary of missing data for categorical columns\n",
    "print(\"\\nMissing Data Summary for Categorical Columns:\")\n",
    "for column in categorical_missing:\n",
    "    print(f\"{column}: {missing_summary[column]} missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222f600",
   "metadata": {},
   "source": [
    "I notice that chatgpt used a way more complicated approach than they discussed in the lecture, even after  I gave it a hint. SO I did a test using just .isna(), and found they directed to the same result, while .isna() provides a full list, chatgpt' solution only listed the missing one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe7b22",
   "metadata": {},
   "source": [
    "4. Since this data doesn't have missing numerical data, so we will be working on another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34593a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "# Read the CSV from the URL using 'latin1' encoding\n",
    "df = pd.read_csv(url, encoding='latin1')\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(df)\n",
    "\n",
    "# Get missing values count using .isna()\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Filter out columns with missing values\n",
    "missing_summary = missing_values[missing_values > 0]\n",
    "\n",
    "# Separate numerical and categorical columns with missing values\n",
    "numerical_missing = [col for col in missing_summary.index if pd.api.types.is_numeric_dtype(df[col])]\n",
    "categorical_missing = [col for col in missing_summary.index if pd.api.types.is_object_dtype(df[col])]\n",
    "\n",
    "# Print the summary of missing data for numerical columns\n",
    "print(\"Missing Data Summary for Numerical Columns:\")\n",
    "for column in numerical_missing:\n",
    "    print(f\"{column}: {missing_summary[column]} missing\")\n",
    "\n",
    "# Print the summary of missing data for categorical columns\n",
    "print(\"\\nMissing Data Summary for Categorical Columns:\")\n",
    "for column in categorical_missing:\n",
    "    print(f\"{column}: {missing_summary[column]} missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d5948",
   "metadata": {},
   "source": [
    " df.shape() is a function that gives how many rows and columns a dataset has. df.descrribe() is a much more complicated function that provides a summary of numerical columns but can also provide categorical data. For example, it can return the frequency, and how many times a certain word or symbol repeats.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d13100",
   "metadata": {},
   "source": [
    "5. \"()\" distinguishes attribute and method. df.shape is an attribute that gives the shape of the dataset without need to execute it. However, df.describe() is analytical, it is a method that needs to go through every data and return both categorical and numerical properties of the dataset. Note that df.shape() and df.describe are incorrect usages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556fc3b",
   "metadata": {},
   "source": [
    "# Post Lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ea226",
   "metadata": {},
   "source": [
    "6. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac2774",
   "metadata": {},
   "source": [
    "\"count\" is used to count up how many valid data(total data - missingness data) in a dataset that helps to understand how many valid data is availble. \n",
    "\n",
    "\"mean\" is the average of all numerical data in a column. Mathematically, it equals to the sum of all data divided by the number non-null data\n",
    "\n",
    "\"std\" stands for standard deviation, it's a measure of how wide the data spreads out in a column. The higher std is, the wider the data spread. \n",
    "\n",
    "\"min\" simply means the minimum data in the column, it is used to find the potential outlier(along with quartile). \n",
    "\n",
    "\"25%\" aka the first quartile(Q1), which is the first 25% of the data listed from smallest to largest\n",
    "\n",
    "\"50%\" is the median of the data. However sometimes the median may not be an existing data if there are even number of data. For example, the median of {1, 4, 5, 7} is 4.5, which the mean between the middle two data. \n",
    "\n",
    "\"75%\" similarly, it's the third quartile(Q3), representing the upper half of the data. \n",
    "\n",
    "\"max\" the largest value in the column, also used to identify potential outliers. \n",
    "\n",
    "*The range of the data is from min to max, and within the range, we divide the data into 4 equal parts for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa405f",
   "metadata": {},
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a123275",
   "metadata": {},
   "source": [
    "1)By definition df.dropna() is used to delete the rows that contains missing data. On the other hand del del df['col'] is used to delete the entire column that has too many missing data. For example, if there are 20 rows in a 200 rows dataset that miss different columns of data, it is preferred to use df.dropna(). We can still study the rest of the data since there should be no missing data. \n",
    "\n",
    "2)This is the complete oppposite case than 1), if the column \"age\"(defined arbitrarily) has 150 missing data, then it might not be meaningul to study, instead of deleting every row, so we use del df.['col'] to remove the entire column so that we can still study the rest. \n",
    "\n",
    "3)In particular cases, we have a lot of missing data in a column, but some rows may only contain missing data in this column, which can be used to study the dataset after we delete that column. However, if we delete those rows first, the study may not represent the entire(or majority) of the dataset. As a result, the order where we apply those two has significant impact on the following study. \n",
    "\n",
    "4)As discussed in 2), after deleting one column, there might be some missing cells(assume not in the same column), so we might want to use df.dropna() to delete additional rows with missing data to ensure we eliminate all missing data. Therefore, a combination of both methods is an efficient way to modify the dataset to the way we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0eb45",
   "metadata": {},
   "source": [
    "8. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903473b",
   "metadata": {},
   "source": [
    "1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = df.groupby('sex')['age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fecfbb",
   "metadata": {},
   "source": [
    "There are two different methods contained, firstly, .groupby means to select the column sex, in the case given by chatgpt. Secondly, .describe() is a method referring to the second column, denoted[\"col2\"], it gives the basic statistical term discussed in previous session. In this case, we are analyzing the pattern of ages on titanic, with separation of sex, the simple summary is displayed in quartile form.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e626460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Drop rows where the 'age' column has missing (NaN) values\n",
    "df_cleaned = df.dropna(subset=['age'])\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group after cleaning missing data\n",
    "grouped_summary = df_cleaned.groupby('sex')['age'].describe()\n",
    "\n",
    "# Display the result\n",
    "grouped_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827d5d1",
   "metadata": {},
   "source": [
    "Something interesting happened here. The comparison shows that groupby() and .describe() automatically delete (NaN) data, so we don't need to use dropna () manually. I asked chatgpt this discovery, it stucked for a while, then agreed with my opinion. Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = df.groupby('alive')['age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c572d9",
   "metadata": {},
   "source": [
    "In this example, I grabbed the infomation of survivors with respect to ages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ba4c0",
   "metadata": {},
   "source": [
    "2)As discussed above, df.describe() does automatically remove missing data, and count is sort of a built-in counter within the frame of df.describe() that shares the feature that df.describe(). So the output of count is the data after all missingness are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d008d1a",
   "metadata": {},
   "source": [
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ad485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "print(url)\n",
    "\n",
    "df = pd.read_csv(url, encoding='latin1') #latin1 = ISO-8859-1\n",
    "print(df.shape) #To print out in the format of a table \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c8274",
   "metadata": {},
   "source": [
    "Chatgpt simply asked me to import pandas as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b62b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B\n",
    "\n",
    "import pandas as py\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "print(url)\n",
    "\n",
    "df = pd.read_csv(url, encoding='latin1') #latin1 = ISO-8859-1\n",
    "print(df.shape) #To print out in the format of a table \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18df9b",
   "metadata": {},
   "source": [
    "Surprisingly, after giving two solutions about changing the code, it potentially realizes that the url might have a typo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = Df.groupby('alive')['age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9a529",
   "metadata": {},
   "source": [
    "Chatgpt gives the right solution to change to df, even if I did not show chatgpt the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = df.groupby('alive')['age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3abb988",
   "metadata": {},
   "source": [
    "I copied the wrong code from C with the error required in D, again chatgpt does recognize the error that \"(\" was not closed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2aecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#E\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = df.groupby('Sex')['age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298890fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = df.groupby('sex')['Age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeec789",
   "metadata": {},
   "source": [
    "In both cases, chatgpt gives the same explanation that pandas is case-sensitive, so when we apply these methods, make sure it follows the headings in the url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeebe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column for each group\n",
    "grouped_summary = titanic_df.groupby('sex')['age'].describe()\n",
    "\n",
    "# Display the result explicitly\n",
    "grouped_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5bd10",
   "metadata": {},
   "source": [
    "We did not define titanic_df in the code, so obviously it is not recognize when the code is executed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e2962",
   "metadata": {},
   "source": [
    "I did read question 9, I acknowledge that I have not read the wiki-textbook yet, but I will do for the sake of understaning course materials. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff484e61",
   "metadata": {},
   "source": [
    "Summary of Chatgpt\n",
    "\n",
    "1. Working with Datasets in Python:\n",
    "You encountered issues loading datasets using pd.read_csv() and learned to ensure pandas (pd) is correctly imported and the correct URL and column names are used.\n",
    "We discussed the use of encoding (specifically latin1/ISO-8859-1) when loading datasets and its efficiency.\n",
    "You worked on loading the Titanic dataset and the Amazon Books dataset, resolving various issues with column names, typos, and importing pandas.\n",
    "2. Grouping and Describing Data:\n",
    "We explored how to group data using groupby() and generate descriptive statistics with describe().\n",
    "You learned how both methods handle missing data automatically (no need to manually drop missing values beforehand).\n",
    "Example: Grouping Titanic data by sex and describing the age column.\n",
    "3. Common Mistakes:\n",
    "Issues related to case sensitivity (e.g., using 'Age' instead of 'age', or 'Sex' instead of 'sex').\n",
    "Misnamed variables, such as using titanic_df instead of df.\n",
    "4. Pandas Functions:\n",
    "We discussed the meaning of df.shape (rows and columns) and df.describe() (summary statistics).\n",
    "Clarified the meaning of count, mean, std, min, 25%, 50%, 75%, and max in the context of descriptive statistics.\n",
    "Explained why certain methods like df.describe() automatically exclude missing values and when dropna() might be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e0c14",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e362cc-073c-8011-a90e-6e2baf7c5d53"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
